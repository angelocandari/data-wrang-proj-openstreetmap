{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Case Study\n",
    "\n",
    "## Introduction\n",
    "<p>I am to investigate data set from a location of my choosing from openstreetmap, identify problems, clean it and store the data in SQL. In addition, I am to propose ideas on how to improve the data. This investigation is a practice project needed to complete the Data Analyst Nanodegree from Udacity.\n",
    "</p>\n",
    "\n",
    "### Location\n",
    "<p>I chose Auckland, New Zealand as my location for my investigation because I have been planning to take a trip here for sometime now. I would like to take the opportunity to get myself familiar with the place by using it as an example for this project</p>\n",
    "- [www.openstreetmap.org/node/292806332](https://www.openstreetmap.org/node/292806332)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0632': set(['15 Arrenway Dr, Rosedale, Auckland 0632']),\n",
      " u'1010\\u65b0\\u897f\\u862d': set([u'38 Lorne St, Auckland, 1010\\u65b0\\u897f\\u862d']),\n",
      " '16': set(['State Highway 16']),\n",
      " '2': set(['State Highway 2']),\n",
      " '22': set(['State Highway 22']),\n",
      " '26': set(['26']),\n",
      " 'Auckland': set(['Exmouth Road, Northcote, Auckland']),\n",
      " 'Ave': set(['Brennan Avenue',\n",
      "             'Delta Avenue',\n",
      "             'Erson Avenue',\n",
      "             'Gillies Avenue',\n",
      "             'Vitasovich Avenue',\n",
      "             'Waverley Avenue']),\n",
      " 'Broadway': set(['Broadway']),\n",
      " 'Circle': set(['Leybourne Circle']),\n",
      " 'Close': set(['Challen Close', 'Court Town Close', 'Regia Close']),\n",
      " 'Coronation': set(['Coronation']),\n",
      " 'Court': set(['Fantail Court', 'Palm Court', 'Palmgreen Court']),\n",
      " 'Cove': set(['Clearwater Cove']),\n",
      " 'Cr': set(['Marjorie Jayne Crescent']),\n",
      " 'Cresent': set(['Tawa Crescent']),\n",
      " 'Crest': set(['The Crescent']),\n",
      " 'East': set(['Customs Street East',\n",
      "              'Durham Street East',\n",
      "              'Greenlane East',\n",
      "              'Pakenham Street East',\n",
      "              'Sylvan Avenue East',\n",
      "              'Victoria Street East',\n",
      "              'Virginia Avenue East',\n",
      "              'Wellesley Street East']),\n",
      " 'Esplanade': set(['The Esplanade']),\n",
      " 'Expressway': set(['Albany Expressway']),\n",
      " 'Gardens': set(['Westminster Gardens']),\n",
      " 'Hill': set(['College Hill']),\n",
      " 'Howick)': set(['Fisher Parade (Howick)']),\n",
      " 'Hurstmere': set(['Hurstmere']),\n",
      " 'Hwy': set(['Main Highway']),\n",
      " 'Mall': set(['Onehunga Mall']),\n",
      " 'Motorway': set(['Auckland Southern Motorway']),\n",
      " 'Parade': set(['Fisher Parade',\n",
      "                'King Edward Parade',\n",
      "                'Marine Parade',\n",
      "                'The Parade']),\n",
      " 'Plc,': set(['Cnr Street Lukes Road & Wagener Place']),\n",
      " 'Ponsonby': set(['Ponsonby']),\n",
      " 'Rd': set(['Botany Road',\n",
      "            'Coster Road',\n",
      "            'New North Road',\n",
      "            'Ponsonby Road',\n",
      "            'Richmond Road']),\n",
      " 'Redwood': set(['Redwood']),\n",
      " 'Rise': set(['Bampton Rise', 'Pacific Rise']),\n",
      " 'School': set(['Red Beach Primary School']),\n",
      " 'South': set(['Grange Road South']),\n",
      " 'Square': set(['Beresford Square',\n",
      "                'Mangere Town Square',\n",
      "                'Queen Elizabeth II Square']),\n",
      " 'St': set(['Balm Street', 'Queen Street', 'hardinge Street']),\n",
      " 'St.': set(['Queen Street']),\n",
      " 'Strand': set(['The Strand']),\n",
      " 'Strret': set(['Cracroft Street']),\n",
      " 'Subritzky': set(['Subritzky']),\n",
      " 'Tai': set(['Ara Tai']),\n",
      " 'Terrace': set(['Poynton Terrace',\n",
      "                 'Quest Terrace',\n",
      "                 'Scarborough Terrace',\n",
      "                 'Seaview Terrace',\n",
      "                 'Shea Terrace',\n",
      "                 'Sunset Terrace',\n",
      "                 'Taunton Terrace']),\n",
      " 'W': set(['Victoria Street W']),\n",
      " 'Wellington': set(['Waipuna Road, Mt Wellington']),\n",
      " 'West': set(['Crayford Street West',\n",
      "              'Customs Street West',\n",
      "              'Green Lane West',\n",
      "              'Sylvan Avenue West',\n",
      "              'Tironui Station Road West',\n",
      "              'Victoria Street West',\n",
      "              'Wellesley Street West',\n",
      "              'Westmoreland Street West']),\n",
      " 'Wharf': set(['Princes Wharf']),\n",
      " 'Zealand': set(['New Zealand']),\n",
      " 'beach': set(['Little Oneroa Beach']),\n",
      " 'ln': set(['Fort Lane']),\n",
      " 'road': set(['hekerua Road']),\n",
      " 'st': set(['Queen Street']),\n",
      " 'street': set(['Durham Street', 'Gore Street', 'Haughey Street']),\n",
      " 'way': set(['Kanona Way'])}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import xml.etree.cElementTree as ET\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "file_sample = \"auckland_new-zealand-sample.osm\"\n",
    "file_actual = \"auckland_new-zealand.osm\"\n",
    "\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "expected = [\"Avenue\", \"Crescent\", \"Drive\", \"Highway\", \"Lane\", \"Place\", \"Road\", \"Street\", \"Way\"]\n",
    "\n",
    "mapping = {\n",
    "    \"street\": \"Street\",\n",
    "    \"st\": \"Street\",\n",
    "    \"st.\": \"Street\",\n",
    "    \"rd\": \"Road\",\n",
    "    \"road\": \"Road\",\n",
    "    \"strret\": \"Street\",\n",
    "    \"cr\": \"Crescent\",\n",
    "    \"cresent\": \"Crescent\",\n",
    "    \"crest\": \"Crescent\",\n",
    "    \"hwy\": \"Highway\",\n",
    "    \"ave\": \"Avenue\",\n",
    "    \"plc,\": \"Place\",\n",
    "    \"beach\": \"Beach\",\n",
    "    \"way\": \"Way\",\n",
    "    \"ln\": \"Lane\"\n",
    "}\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    name_a = name.split(\" \")\n",
    "\n",
    "    for w in range(len(name_a)):\n",
    "        if name_a[w].lower() in mapping.keys():\n",
    "            name_a[w] = mapping[name_a[w].lower()]\n",
    "    name = \" \".join(name_a)\n",
    "    \n",
    "    return name\n",
    "            \n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            new_name = update_name(street_name, mapping)\n",
    "            street_types[street_type].add(new_name)\n",
    "    \n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == 'addr:street')\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, 'r')\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=('start',)):\n",
    "        if elem.tag == \"way\" or elem.tag == 'node':\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "st_types = audit(actual_sample)\n",
    "\n",
    "pprint.pprint(dict(st_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems Encountered in Your Map\n",
    "<p>Running the data set through the code, I explored the data and took notes of some problems that I have encountered in the map that I have chosen.</p>\n",
    "- Mispelled Names\n",
    "- Incorrect Capitalization\n",
    "- Abbreviated Names\n",
    "- Problematic Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import cerberus\n",
    "import schema\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema.schema\n",
    "\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, \n",
    "                  way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, \n",
    "                  default_tag_type='regular'):\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []\n",
    "    \n",
    "    if element.tag == 'node':\n",
    "        for elem in NODE_FIELDS:\n",
    "            if element.get(elem):\n",
    "                node_attribs[elem] = element.attrib[elem]\n",
    "            else:\n",
    "                return \n",
    "        for elem in element:\n",
    "            item = {}\n",
    "            if PROBLEMCHARS.match(elem.attrib['k']):\n",
    "                continue\n",
    "            elif LOWER_COLON.match(elem.attrib['k']):\n",
    "                item['id'] = element.attrib['id']\n",
    "                item['key'] = elem.attrib['k'].split(':')[1]\n",
    "                item['type'] = elem.attrib['k'].split(':')[0]\n",
    "                if is_street_name(elem):\n",
    "                    item['value'] = update_name(elem.attrib['v'], mapping)\n",
    "                else:\n",
    "                    item['value'] = elem.attrib['v']\n",
    "            else:\n",
    "                item['id'] = element.attrib['id']\n",
    "                item['key'] = elem.attrib['k']\n",
    "                item['type'] = 'regular'\n",
    "                if is_street_name(elem):\n",
    "                    item['value'] = update_name(elem.attrib['v'], mapping)\n",
    "                else:\n",
    "                    item['value'] = elem.attrib['v']\n",
    "            tags.append(item)\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    \n",
    "    if element.tag == 'way':\n",
    "        i = 0\n",
    "        for elem in element.attrib:\n",
    "            if elem in WAY_FIELDS:\n",
    "                way_attribs[elem] = element.attrib[elem]\n",
    "        for elem in element:\n",
    "            item= {}\n",
    "            item_nd = {}\n",
    "            if elem.tag == \"tag\":\n",
    "                if LOWER_COLON.match(elem.attrib[\"k\"]):\n",
    "                    item[\"id\"] = element.attrib[\"id\"]\n",
    "                    item[\"key\"] = elem.attrib[\"k\"].split(\":\", 1)[1]\n",
    "                    item[\"type\"] = elem.attrib[\"k\"].split(\":\", 1)[0]\n",
    "                    if is_street_name(elem):\n",
    "                        item['value'] = update_name(elem.attrib['v'], mapping)\n",
    "                    else:\n",
    "                        item[\"value\"] = elem.attrib[\"v\"]\n",
    "                else:\n",
    "                    item[\"id\"] = element.attrib[\"id\"]\n",
    "                    item[\"key\"] = elem.attrib[\"k\"]\n",
    "                    item[\"type\"] = \"regular\"\n",
    "                    if is_street_name(elem):\n",
    "                        item['value'] = update_name(elem.attrib['v'], mapping)\n",
    "                    else:\n",
    "                        item[\"value\"] = elem.attrib[\"v\"]\n",
    "                tags.append(item)\n",
    "                \n",
    "            if elem.tag == \"nd\":\n",
    "                item_nd[\"id\"] = int(element.attrib[\"id\"])\n",
    "                item_nd[\"node_id\"] = int(elem.attrib[\"ref\"])\n",
    "                item_nd[\"position\"] = i\n",
    "                i += 1\n",
    "                \n",
    "                way_nodes.append(item_nd)\n",
    "        return {\"way\": way_attribs, \"way_nodes\": way_nodes, \"way_tags\": tags}\n",
    "                    \n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "            \n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "            \n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    def writerow(self,row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v, in row.iteritems()\n",
    "        })\n",
    "        \n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)            \n",
    "    \n",
    "def process_map(file_in, validate):\n",
    "    \n",
    "    with codecs.open(NODES_PATH, \"w\") as nodes_file, \\\n",
    "    codecs.open(NODE_TAGS_PATH, \"w\") as node_tags_file, \\\n",
    "    codecs.open(WAYS_PATH, \"w\") as ways_file, \\\n",
    "    codecs.open(WAY_NODES_PATH, \"w\") as way_nodes_file, \\\n",
    "    codecs.open(WAY_TAGS_PATH, \"w\") as way_tags_file:\n",
    "        \n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(node_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "        \n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "        \n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == \"way\":\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el[\"way_nodes\"])\n",
    "                    way_tags_writer.writerows(el[\"way_tags\"])\n",
    "#         pprint.pprint(el)\n",
    "    \n",
    "process_map(file_actual, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(715398,\n",
      " -37.3017871,\n",
      " 175.0614049,\n",
      " u'ddixon',\n",
      " 35638,\n",
      " u'2',\n",
      " 3171871,\n",
      " u'2009-11-20T21:19:57Z')\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import csv\n",
    "from pprint import pprint\n",
    "\n",
    "sqlite_file = 'project.db'\n",
    "db = sqlite3.connect(sqlite_file) # connects to database\n",
    "cur = db.cursor()\n",
    "\n",
    "cur.execute('''DROP TABLE IF EXISTS nodes_tags''')\n",
    "cur.execute('''DROP TABLE IF EXISTS ways''')\n",
    "cur.execute('''DROP TABLE IF EXISTS ways_nodes''')\n",
    "cur.execute('''DROP TABLE IF EXISTS ways_tags''')\n",
    "cur.execute('''DROP TABLE IF EXISTS nodes''')\n",
    "db.commit()\n",
    "\n",
    "cur.execute('''CREATE TABLE nodes_tags(id INTEGER, key TEXT, value TEXT, type TEXT)''')\n",
    "cur.execute('''CREATE TABLE ways(id INTEGER, user TEXT, uid INTEGER, version TEXT, changeset INTEGER, timestamp TEXT)''')\n",
    "cur.execute('''CREATE TABLE ways_nodes(id INTEGER, node_id INTEGER, position INTEGER)''')\n",
    "cur.execute('''CREATE TABLE ways_tags(id INTEGER, key TEXT, value TEXT, type TEXT)''')\n",
    "cur.execute('''CREATE TABLE nodes(id INTEGER, lat REAL, lon REAL, user TEXT, uid INTEGER, version TEXT, changeset INTEGER, timestamp TEXT)''')\n",
    "db.commit()\n",
    "\n",
    "with open('nodes_tags.csv', 'rb') as f:\n",
    "    dr = csv.DictReader(f)\n",
    "    nt_db = [(i['id'], i['key'], i['value'].decode('utf-8'), i['type']) for i in dr]\n",
    "\n",
    "with open('ways.csv', 'rb') as f:\n",
    "    dr = csv.DictReader(f)\n",
    "    wa_db = [(i['id'], i['user'].decode('utf-8'), i['uid'], i['version'], i['changeset'], i['timestamp']) for i in dr]\n",
    "\n",
    "with open('ways_nodes.csv', 'rb') as f:\n",
    "    dr = csv.DictReader(f)\n",
    "    wn_db = [(i['id'], i['node_id'], i['position']) for i in dr]\n",
    "    \n",
    "with open('ways_tags.csv', 'rb') as f:\n",
    "    dr = csv.DictReader(f)\n",
    "    wt_db = [(i['id'], i['key'], i['value'].decode('utf-8'), i['type']) for i in dr]\n",
    "        \n",
    "with open('nodes.csv', 'rb') as f:\n",
    "    dr = csv.DictReader(f)\n",
    "    no_db = [(i['id'], i['lat'], i['lon'], i['user'].decode('utf-8'), i['uid'], i['version'], i['changeset'], i['timestamp']) for i in dr]\n",
    "\n",
    "cur.executemany('INSERT INTO nodes_tags(id, key, value, type) VALUES (?, ?, ?, ?);', nt_db)\n",
    "cur.executemany('INSERT INTO ways(id, user, uid, version, changeset, timestamp) VALUES (?, ?, ?, ?, ?, ?);', wa_db)\n",
    "cur.executemany('INSERT INTO ways_nodes(id, node_id, position) VALUES (?, ?, ?);', wn_db)\n",
    "cur.executemany('INSERT INTO ways_tags(id, key, value, type) VALUES (?, ?, ?, ?);', wt_db)\n",
    "cur.executemany('INSERT INTO nodes(id, lat, lon, user, uid, version, changeset, timestamp) VALUES (?, ?, ?, ?, ?, ?, ?, ?);', no_db)\n",
    "db.commit()\n",
    "\n",
    "cur.execute('SELECT * FROM nodes')\n",
    "all_rows = cur.fetchone()\n",
    "pprint(all_rows)\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'problemchars': 0, 'lower': 88852, 'other': 76919, 'lower_colon': 1960}\n"
     ]
    }
   ],
   "source": [
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "def key_type(element,keys):\n",
    "    if element.tag == 'tag':\n",
    "        query = element.attrib['k']\n",
    "        if lower.search(query):\n",
    "            keys['lower'] += 1\n",
    "        elif lower_colon.search(query):\n",
    "            keys['lower_colon'] += 1\n",
    "        elif problemchars.search(query):\n",
    "            keys['problemchars'] += 1\n",
    "        else:\n",
    "            keys['other'] += 1\n",
    "        pass\n",
    "    return keys\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {'lower': 0, 'lower_colon': 0, 'problemchars': 0, 'other': 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "    return keys\n",
    "\n",
    "keys = process_map(file_current)\n",
    "print keys\n",
    "\n",
    "def count_tags(filename):\n",
    "    tags = {}\n",
    "    \n",
    "    for i, elem in ET.iterparse(filename):\n",
    "        if elem.tag not in tags.keys():\n",
    "            tags[elem.tag] = 1\n",
    "        else:\n",
    "            tags[elem.tag] += 1\n",
    "    return tags\n",
    "\n",
    "tags = count_tags(file_current)\n",
    "print tags"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
