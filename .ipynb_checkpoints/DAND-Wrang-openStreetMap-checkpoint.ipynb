{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Case Study\n",
    "\n",
    "## Introduction\n",
    "<p>My task is to investigate a data set from a location of my choosing from openstreetmap. I need identify problems, clean it and store the data in SQL. Then, I am to explore the data programmatically and propose ideas on how to improve the data set. This investigation is a practice project needed to complete the Data Analyst Nanodegree from Udacity.\n",
    "</p>\n",
    "\n",
    "### Location\n",
    "<p>I chose Auckland, New Zealand as my location for my investigation because I have been planning to take a trip here for sometime now. I would like to take the opportunity to get myself familiar with the place by using it as an example for this project.</p>\n",
    "- [www.openstreetmap.org/node/292806332](https://www.openstreetmap.org/node/292806332)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0632': set(['15 Arrenway Dr, Rosedale, Auckland 0632']),\n",
      " u'1010\\u65b0\\u897f\\u862d': set([u'38 Lorne St, Auckland, 1010\\u65b0\\u897f\\u862d']),\n",
      " '16': set(['State Highway 16']),\n",
      " '2': set(['State Highway 2']),\n",
      " '22': set(['State Highway 22']),\n",
      " '26': set(['26']),\n",
      " 'Auckland': set(['Exmouth Road, Northcote, Auckland']),\n",
      " 'Ave': set(['Brennan Avenue',\n",
      "             'Delta Avenue',\n",
      "             'Erson Avenue',\n",
      "             'Gillies Avenue',\n",
      "             'Vitasovich Avenue',\n",
      "             'Waverley Avenue']),\n",
      " 'Broadway': set(['Broadway']),\n",
      " 'Circle': set(['Leybourne Circle']),\n",
      " 'Close': set(['Challen Close', 'Court Town Close', 'Regia Close']),\n",
      " 'Coronation': set(['Coronation']),\n",
      " 'Court': set(['Fantail Court', 'Palm Court', 'Palmgreen Court']),\n",
      " 'Cove': set(['Clearwater Cove']),\n",
      " 'Cr': set(['Marjorie Jayne Crescent']),\n",
      " 'Cresent': set(['Tawa Crescent']),\n",
      " 'Crest': set(['The Crescent']),\n",
      " 'East': set(['Customs Street East',\n",
      "              'Durham Street East',\n",
      "              'Greenlane East',\n",
      "              'Pakenham Street East',\n",
      "              'Sylvan Avenue East',\n",
      "              'Victoria Street East',\n",
      "              'Virginia Avenue East',\n",
      "              'Wellesley Street East']),\n",
      " 'Esplanade': set(['The Esplanade']),\n",
      " 'Expressway': set(['Albany Expressway']),\n",
      " 'Gardens': set(['Westminster Gardens']),\n",
      " 'Hill': set(['College Hill']),\n",
      " 'Howick)': set(['Fisher Parade (Howick)']),\n",
      " 'Hurstmere': set(['Hurstmere']),\n",
      " 'Hwy': set(['Main Highway']),\n",
      " 'Mall': set(['Onehunga Mall']),\n",
      " 'Motorway': set(['Auckland Southern Motorway']),\n",
      " 'Parade': set(['Fisher Parade',\n",
      "                'King Edward Parade',\n",
      "                'Marine Parade',\n",
      "                'The Parade']),\n",
      " 'Plc,': set(['Cnr Street Lukes Road & Wagener Place']),\n",
      " 'Ponsonby': set(['Ponsonby']),\n",
      " 'Rd': set(['Botany Road',\n",
      "            'Coster Road',\n",
      "            'New North Road',\n",
      "            'Ponsonby Road',\n",
      "            'Richmond Road']),\n",
      " 'Redwood': set(['Redwood']),\n",
      " 'Rise': set(['Bampton Rise', 'Pacific Rise']),\n",
      " 'School': set(['Red Beach Primary School']),\n",
      " 'South': set(['Grange Road South']),\n",
      " 'Square': set(['Beresford Square',\n",
      "                'Mangere Town Square',\n",
      "                'Queen Elizabeth II Square']),\n",
      " 'St': set(['Balm Street', 'Queen Street', 'hardinge Street']),\n",
      " 'St.': set(['Queen Street']),\n",
      " 'Strand': set(['The Strand']),\n",
      " 'Strret': set(['Cracroft Street']),\n",
      " 'Subritzky': set(['Subritzky']),\n",
      " 'Tai': set(['Ara Tai']),\n",
      " 'Terrace': set(['Poynton Terrace',\n",
      "                 'Quest Terrace',\n",
      "                 'Scarborough Terrace',\n",
      "                 'Seaview Terrace',\n",
      "                 'Shea Terrace',\n",
      "                 'Sunset Terrace',\n",
      "                 'Taunton Terrace']),\n",
      " 'W': set(['Victoria Street W']),\n",
      " 'Wellington': set(['Waipuna Road, Mt Wellington']),\n",
      " 'West': set(['Crayford Street West',\n",
      "              'Customs Street West',\n",
      "              'Green Lane West',\n",
      "              'Sylvan Avenue West',\n",
      "              'Tironui Station Road West',\n",
      "              'Victoria Street West',\n",
      "              'Wellesley Street West',\n",
      "              'Westmoreland Street West']),\n",
      " 'Wharf': set(['Princes Wharf']),\n",
      " 'Zealand': set(['New Zealand']),\n",
      " 'beach': set(['Little Oneroa Beach']),\n",
      " 'ln': set(['Fort Lane']),\n",
      " 'road': set(['hekerua Road']),\n",
      " 'st': set(['Queen Street']),\n",
      " 'street': set(['Durham Street', 'Gore Street', 'Haughey Street']),\n",
      " 'way': set(['Kanona Way'])}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import xml.etree.cElementTree as ET\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "file_sample = \"auckland_new-zealand-sample.osm\" # Sample extract for testing.\n",
    "file_actual = \"auckland_new-zealand.osm\" # Main file.\n",
    "\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE) # Searches the last word of a street address.\n",
    "\n",
    "# Expected street names that expect and are more frequently used in the dataset.\n",
    "expected = [\"Avenue\", \"Crescent\", \"Drive\", \"Highway\", \"Lane\", \"Place\", \"Road\", \"Street\", \"Way\"]\n",
    "\n",
    "mapping = { # Mapping is the dict that I use for reference when I update the street names.\n",
    "    \"street\": \"Street\",\n",
    "    \"st\": \"Street\",\n",
    "    \"st.\": \"Street\",\n",
    "    \"rd\": \"Road\",\n",
    "    \"road\": \"Road\",\n",
    "    \"strret\": \"Street\",\n",
    "    \"cr\": \"Crescent\",\n",
    "    \"cresent\": \"Crescent\",\n",
    "    \"crest\": \"Crescent\",\n",
    "    \"hwy\": \"Highway\",\n",
    "    \"ave\": \"Avenue\",\n",
    "    \"plc,\": \"Place\",\n",
    "    \"beach\": \"Beach\",\n",
    "    \"way\": \"Way\",\n",
    "    \"ln\": \"Lane\"\n",
    "}\n",
    "\n",
    "def update_name(name, mapping): # Updates street name according to mapping dict.\n",
    "    name_a = name.split(\" \")\n",
    "\n",
    "    for w in range(len(name_a)):\n",
    "        if name_a[w].lower() in mapping.keys():\n",
    "            name_a[w] = mapping[name_a[w].lower()]\n",
    "    name = \" \".join(name_a)\n",
    "    \n",
    "    return name\n",
    "            \n",
    "def audit_street_type(street_types, street_name): # Audits addresses. Excludes expected and updates names.\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            new_name = update_name(street_name, mapping)\n",
    "            street_types[street_type].add(new_name)\n",
    "    \n",
    "def is_street_name(elem): # Checks if element is a street addresses.\n",
    "    return (elem.attrib['k'] == 'addr:street')\n",
    "\n",
    "def audit(osmfile): # Initiates the audit, searches for sreet addresses and organizes them for review.\n",
    "    osm_file = open(osmfile, 'r')\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=('start',)):\n",
    "        if elem.tag == \"way\" or elem.tag == 'node':\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "st_types = audit(file_actual) # Element that holds the audited data.\n",
    "\n",
    "pprint.pprint(dict(st_types)) # Prints street names before and after the update."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems Encountered in Your Map\n",
    "<p>To find and fix the streetnames in the map data, I ran the entire map data through a function that groups all street addresses into a dictionary according to the different variations used in the map. I filter the street names that I expect to be used and review the street addresses that I don't expect. Below are the problems that I will focus on for my audit.</p>\n",
    "\n",
    "- **Mispelled Names.** Some street names are spelled incorrectly like *Strreet*.\n",
    "- **Incorrect Capitalization.** Some street names are not capitalized consistently like *road*.\n",
    "- **Abbreviated Names.** Some of the street names are abbreviated. I would prefer not to use abbreviations of their names. Instead of *Hwy*, use *Highway*.\n",
    "- **Problematic Format.** Street names with problematic characters will be ignored.\n",
    "\n",
    "<p>I start fixing the data set by using the function *update_name*, which revises the streetnames according to my specifications that are outlined in *mapping*. Once I am satisfied with my data, I process the data in an xml structure accordng to the example schema. I then turn xml into csv. Once the CSVs are generated and validated, I then import the data into an SQL database to begin my exploration.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import cerberus\n",
    "import schema\n",
    "\n",
    "NODES_PATH = \"nodes.csv\" # These are the csv file paths.\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema.schema # Example schema that validates the data model.\n",
    "\n",
    "# Column Headers to populate the data set.\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, # Creates the XML structure. Updates street names.\n",
    "                  way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, \n",
    "                  default_tag_type='regular'):\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []\n",
    "    \n",
    "    if element.tag == 'node': # Nodes.\n",
    "        for elem in NODE_FIELDS:\n",
    "            if element.get(elem):\n",
    "                node_attribs[elem] = element.attrib[elem]\n",
    "            else: # Some nodes does not have attributes. This ignores them.\n",
    "                return\n",
    "            \n",
    "        for elem in element:\n",
    "            item = {}\n",
    "            if PROBLEMCHARS.match(elem.attrib['k']): # Ignores problematic characters.\n",
    "                continue\n",
    "            elif LOWER_COLON.match(elem.attrib['k']): # If the element has a ':'.\n",
    "                item['id'] = element.attrib['id']\n",
    "                item['key'] = elem.attrib['k'].split(':')[1]\n",
    "                item['type'] = elem.attrib['k'].split(':')[0]\n",
    "                if is_street_name(elem):\n",
    "                    item['value'] = update_name(elem.attrib['v'], mapping) # Updates street names.\n",
    "                else:\n",
    "                    item['value'] = elem.attrib['v']\n",
    "            else: # For everythin else.\n",
    "                item['id'] = element.attrib['id']\n",
    "                item['key'] = elem.attrib['k']\n",
    "                item['type'] = 'regular'\n",
    "                if is_street_name(elem):\n",
    "                    item['value'] = update_name(elem.attrib['v'], mapping)\n",
    "                else:\n",
    "                    item['value'] = elem.attrib['v']\n",
    "            tags.append(item)\n",
    "            \n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    \n",
    "    if element.tag == 'way': # Ways.\n",
    "        i = 0 # counter for way_nodes elements. Since we do know how many they are.\n",
    "        for elem in element.attrib:\n",
    "            if elem in WAY_FIELDS:\n",
    "                way_attribs[elem] = element.attrib[elem]\n",
    "                \n",
    "        for elem in element:\n",
    "            item = {}\n",
    "            item_nd = {}\n",
    "            if elem.tag == \"tag\":\n",
    "                if LOWER_COLON.match(elem.attrib[\"k\"]):\n",
    "                    item[\"id\"] = element.attrib[\"id\"]\n",
    "                    item[\"key\"] = elem.attrib[\"k\"].split(\":\", 1)[1]\n",
    "                    item[\"type\"] = elem.attrib[\"k\"].split(\":\", 1)[0]\n",
    "                    if is_street_name(elem):\n",
    "                        item['value'] = update_name(elem.attrib['v'], mapping)\n",
    "                    else:\n",
    "                        item[\"value\"] = elem.attrib[\"v\"]\n",
    "                else:\n",
    "                    item[\"id\"] = element.attrib[\"id\"]\n",
    "                    item[\"key\"] = elem.attrib[\"k\"]\n",
    "                    item[\"type\"] = \"regular\"\n",
    "                    if is_street_name(elem):\n",
    "                        item['value'] = update_name(elem.attrib['v'], mapping)\n",
    "                    else:\n",
    "                        item[\"value\"] = elem.attrib[\"v\"]\n",
    "                tags.append(item)\n",
    "                \n",
    "            if elem.tag == \"nd\":\n",
    "                item_nd[\"id\"] = int(element.attrib[\"id\"])\n",
    "                item_nd[\"node_id\"] = int(elem.attrib[\"ref\"])\n",
    "                item_nd[\"position\"] = i\n",
    "                i += 1\n",
    "                way_nodes.append(item_nd)\n",
    "                \n",
    "        return {\"way\": way_attribs, \"way_nodes\": way_nodes, \"way_tags\": tags}\n",
    "\n",
    "# Helper Functions.\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')): # Efficient parser.\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "            \n",
    "def validate_element(element, validator, schema=SCHEMA): # Validates our data structure.\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "            \n",
    "class UnicodeDictWriter(csv.DictWriter, object): # Helps write the csv.\n",
    "    def writerow(self,row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v, in row.iteritems()\n",
    "        })\n",
    "        \n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)            \n",
    "    \n",
    "def process_map(file_in, validate): # Main function that processes the map data.\n",
    "    \n",
    "    with codecs.open(NODES_PATH, \"w\") as nodes_file, \\ # Opens each csv file.\n",
    "    codecs.open(NODE_TAGS_PATH, \"w\") as node_tags_file, \\\n",
    "    codecs.open(WAYS_PATH, \"w\") as ways_file, \\\n",
    "    codecs.open(WAY_NODES_PATH, \"w\") as way_nodes_file, \\\n",
    "    codecs.open(WAY_TAGS_PATH, \"w\") as way_tags_file:\n",
    "        # CSV writing variables and methods.\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(node_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "        \n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "        \n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')): # CSV writing process.\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == \"way\":\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el[\"way_nodes\"])\n",
    "                    way_tags_writer.writerows(el[\"way_tags\"])\n",
    "    \n",
    "process_map(file_actual, validate=True) # Initiates writing the CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(715398, u'class', u'node', u'regular')\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import csv\n",
    "from pprint import pprint\n",
    "\n",
    "sqlite_file = 'project.db' # File path of the database.\n",
    "db = sqlite3.connect(sqlite_file) # Connects to database\n",
    "cur = db.cursor()\n",
    "\n",
    "# Deletes the tables if they exists.\n",
    "cur.execute('''DROP TABLE IF EXISTS nodes_tags''') \n",
    "cur.execute('''DROP TABLE IF EXISTS ways''')\n",
    "cur.execute('''DROP TABLE IF EXISTS ways_nodes''')\n",
    "cur.execute('''DROP TABLE IF EXISTS ways_tags''')\n",
    "cur.execute('''DROP TABLE IF EXISTS nodes''')\n",
    "db.commit() # Commit is the same as pressing ENTER if you do this in cmd or a terminal.\n",
    "\n",
    "# Creates the tables with corresponding field types.\n",
    "cur.execute('''CREATE TABLE nodes_tags(id INTEGER, key TEXT, value TEXT, type TEXT)''')\n",
    "cur.execute('''CREATE TABLE ways(id INTEGER, user TEXT, uid INTEGER, version TEXT, changeset INTEGER, timestamp TEXT)''')\n",
    "cur.execute('''CREATE TABLE ways_nodes(id INTEGER, node_id INTEGER, position INTEGER)''')\n",
    "cur.execute('''CREATE TABLE ways_tags(id INTEGER, key TEXT, value TEXT, type TEXT)''')\n",
    "cur.execute('''CREATE TABLE nodes(id INTEGER, lat REAL, lon REAL, user TEXT, uid INTEGER, version TEXT, changeset INTEGER, timestamp TEXT)''')\n",
    "db.commit()\n",
    "\n",
    "# Reads the csv data into corresponding variables.\n",
    "with open('nodes_tags.csv', 'rb') as f:\n",
    "    dr = csv.DictReader(f)\n",
    "    nt_db = [(i['id'], i['key'], i['value'].decode('utf-8'), i['type']) for i in dr]\n",
    "\n",
    "with open('ways.csv', 'rb') as f:\n",
    "    dr = csv.DictReader(f)\n",
    "    wa_db = [(i['id'], i['user'].decode('utf-8'), i['uid'], i['version'], i['changeset'], i['timestamp']) for i in dr]\n",
    "\n",
    "with open('ways_nodes.csv', 'rb') as f:\n",
    "    dr = csv.DictReader(f)\n",
    "    wn_db = [(i['id'], i['node_id'], i['position']) for i in dr]\n",
    "    \n",
    "with open('ways_tags.csv', 'rb') as f:\n",
    "    dr = csv.DictReader(f)\n",
    "    wt_db = [(i['id'], i['key'], i['value'].decode('utf-8'), i['type']) for i in dr]\n",
    "        \n",
    "with open('nodes.csv', 'rb') as f:\n",
    "    dr = csv.DictReader(f)\n",
    "    no_db = [(i['id'], i['lat'], i['lon'], i['user'].decode('utf-8'), i['uid'], i['version'], i['changeset'], i['timestamp']) for i in dr]\n",
    "\n",
    "# Inserts data into the database. Row by row.\n",
    "cur.executemany('INSERT INTO nodes_tags(id, key, value, type) VALUES (?, ?, ?, ?);', nt_db)\n",
    "cur.executemany('INSERT INTO ways(id, user, uid, version, changeset, timestamp) VALUES (?, ?, ?, ?, ?, ?);', wa_db)\n",
    "cur.executemany('INSERT INTO ways_nodes(id, node_id, position) VALUES (?, ?, ?);', wn_db)\n",
    "cur.executemany('INSERT INTO ways_tags(id, key, value, type) VALUES (?, ?, ?, ?);', wt_db)\n",
    "cur.executemany('INSERT INTO nodes(id, lat, lon, user, uid, version, changeset, timestamp) VALUES (?, ?, ?, ?, ?, ?, ?, ?);', no_db)\n",
    "db.commit()\n",
    "\n",
    "cur.execute('SELECT * FROM nodes_tags') # Checks one line of the data.\n",
    "all_rows = cur.fetchone()\n",
    "pprint(all_rows)\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the Data\n",
    "### File Size\n",
    "- auckland_new-zealand.osm: 658 MB\n",
    "- project.db: 409 MB\n",
    "- node_tags.csv: 3.67 MB\n",
    "- ways.csv: 20 MB\n",
    "- ways_nodes.csv: 84 MB\n",
    "- ways_tags.csv: 86 MB\n",
    "- nodes.csv: 246 MB\n",
    "\n",
    "### Counts\n",
    "- Number of Unique Users: 953\n",
    "- Number of Nodes: 2,913,110\n",
    "- Number of Ways: 328,159\n",
    "- Number of Hotels: 61\n",
    "- Number of Attractions: 55\n",
    "- Number of Museums: 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database Size: 419012608\n",
      "Ways Count: 328159\n",
      "Nodes Count: 2913110\n",
      "Unique Users Count: 953\n",
      "Total Hotels: 61\n",
      "Total Attractions: 55\n",
      "Total Museums: 13\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import csv\n",
    "from pprint import pprint\n",
    "\n",
    "sqlite_file = 'project.db'\n",
    "db = sqlite3.connect(sqlite_file) # Connects the database. I want my sql executions independent from cells.\n",
    "cur = db.cursor()\n",
    "\n",
    "cur.execute('PRAGMA PAGE_SIZE;') # Programmatically checks the file size of the database.\n",
    "page_size = cur.fetchone()\n",
    "cur.execute('PRAGMA PAGE_COUNT;')\n",
    "page_count = cur.fetchone()\n",
    "database_size = page_size[0] * page_count[0]\n",
    "\n",
    "cur.execute('SELECT COUNT(*) FROM ways;') # Counts the number of ways.\n",
    "count_ways = cur.fetchall()\n",
    "\n",
    "cur.execute('SELECT COUNT(*) FROM nodes;') # Counts the number of nodes.\n",
    "count_nodes = cur.fetchall()\n",
    "\n",
    "cur.execute('SELECT COUNT(DISTINCT(e.uid)) FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) e;')\n",
    "unique_users = cur.fetchall() # Counts the number of unique users.\n",
    "\n",
    "cur.execute('SELECT COUNT(*) FROM nodes_tags WHERE key=\"tourism\" and value=\"hotel\"')\n",
    "count_hotel = cur.fetchall() # Counts the number of hotels in the area.\n",
    "\n",
    "cur.execute('SELECT COUNT(*) FROM nodes_tags WHERE key=\"tourism\" and value=\"attraction\"')\n",
    "count_attraction = cur.fetchall() # Counts the number of attractions.\n",
    "\n",
    "cur.execute('SELECT COUNT(*) FROM nodes_tags WHERE key=\"tourism\" and value=\"museum\"')\n",
    "count_museum = cur.fetchall() # Counts the number of museums.\n",
    "\n",
    "print(\"Database Size: {}\".format(database_size)) # Prints all of the SQL queries above.\n",
    "print(\"Ways Count: {}\".format(count_ways[0][0]))\n",
    "print(\"Nodes Count: {}\".format(count_nodes[0][0]))\n",
    "print(\"Unique Users Count: {}\".format(unique_users[0][0]))\n",
    "print(\"Total Hotels: {}\".format(count_hotel[0][0]))\n",
    "print(\"Total Attractions: {}\".format(count_attraction[0][0]))\n",
    "print(\"Total Museums: {}\".format(count_museum[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Ideas about the Dataset\n",
    "### More descriptive Attractions Markers for Tourists\n",
    "<p>It would be a lot more helpful if tourists attractions are given more detail on their labels. Currently, the tags are labeled as **attractions** are not as helpful as much for traveler to plan their trip. If the attractions have more detail such as **beach**, **monuments** or **nature**, then these would be more helpful for would-be travelers planning a visit to Auckland.</p>\n",
    "\n",
    "<p>Currently, there are 18 types of tourism markers. One of the tourism sites are labeled as *attractions* with 55 markers on Auckland, New Zealand. If these markers are provided with more detail, it could be helpful information to travellers.</p>\n",
    "\n",
    "<p>I suggest that if when users edit, there should be a snippet of text within text field, where the users would input the data, that would encourage the user to add more detail to their markers or labels. Instead of an empty field, it could instead say, \"What can I see here?\".</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types of Tourism markers: 18\n",
      "[(u'viewpoint', 121),\n",
      " (u'motel', 106),\n",
      " (u'information', 80),\n",
      " (u'hotel', 61),\n",
      " (u'attraction', 55),\n",
      " (u'artwork', 38),\n",
      " (u'hostel', 36),\n",
      " (u'camp_site', 31),\n",
      " (u'guest_house', 31),\n",
      " (u'picnic_site', 27),\n",
      " (u'museum', 13),\n",
      " (u'caravan_site', 4),\n",
      " (u'chalet', 4),\n",
      " (u'alpine_hut', 2),\n",
      " (u'gallery', 2),\n",
      " (u'Kennedy Point Ferry Wharf', 1),\n",
      " (u'theme_park', 1),\n",
      " (u'yes', 1)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute('SELECT COUNT(*) \\\n",
    "            FROM \\\n",
    "                (SELECT value, COUNT(*) as num FROM nodes_tags WHERE key=\"tourism\" \\\n",
    "                GROUP BY value ORDER BY num DESC LIMIT 100) u;')\n",
    "tourism = cur.fetchall()\n",
    "\n",
    "cur.execute('SELECT value, COUNT(*) as num FROM nodes_tags \\\n",
    "            WHERE key=\"tourism\" \\\n",
    "            GROUP BY value \\\n",
    "            ORDER BY num DESC')\n",
    "tourism_types = cur.fetchall()\n",
    "\n",
    "print('Types of Tourism markers: {}'.format(tourism[0][0]))\n",
    "pprint(tourism_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "<p>Auckland, New Zealand map is well populated by contributions from active users. But because of the lack of guidelines or motivation to properly fill in the data is affecting the extent of details that each of the users is willing to input. If at the moment of data entry, there would be a descriptive text in a form of a question, users would be more obliged or encourage to place more detail on the data.</p>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
